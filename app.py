
# ============================================================
# DOCKERIZED BUSINESS IMPACT FORECAST SYSTEM
# Project: Sales Forecasting & Optimization
# ============================================================

import pandas as pd
import numpy as np
import json
import os
import logging
from datetime import datetime

# ==========================================
# 1ï¸âƒ£ Logging Setup
# ==========================================
if not os.path.exists("logs"):
    os.makedirs("logs")

logging.basicConfig(
    filename=f"logs/run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

logging.info("ğŸš€ Docker ML System started successfully")

# ==========================================
# 2ï¸âƒ£ Load Dataset
# ==========================================
DATA_PATH = "Business_Impact_Model.csv"

try:
    df = pd.read_csv(DATA_PATH)
    logging.info(f"âœ… Data loaded successfully. Shape: {df.shape}")
except Exception as e:
    logging.error(f"âŒ Error loading data: {e}")
    raise

# ==========================================
# 3ï¸âƒ£ Data Validation
# ==========================================
required_columns = ['Date', 'Revenue_Current', 'Revenue_Optimized', 'Revenue_Change', 'Growth_%']

missing_cols = [col for col in required_columns if col not in df.columns]
if missing_cols:
    logging.error(f"âŒ Missing columns in dataset: {missing_cols}")
    raise ValueError(f"Dataset missing columns: {missing_cols}")

# ==========================================
# 4ï¸âƒ£ Business Intelligence Metrics
# ==========================================
df['Date'] = pd.to_datetime(df['Date'])
df['Efficiency_Index'] = (df['Revenue_Optimized'] / df['Revenue_Current']) * 100
df['Profitability_Score'] = np.where(df['Revenue_Change'] > 0, df['Growth_%'] * 1.1, df['Growth_%'] * 0.9)

summary = {
    "Start_Date": str(df['Date'].min().date()),
    "End_Date": str(df['Date'].max().date()),
    "Total_Records": len(df),
    "Avg_Growth_%": round(df['Growth_%'].mean(), 2),
    "Avg_Efficiency_Index": round(df['Efficiency_Index'].mean(), 2),
    "Avg_Profitability_Score": round(df['Profitability_Score'].mean(), 2)
}

logging.info("ğŸ“Š Summary Metrics calculated successfully")
print(json.dumps(summary, indent=4))

# ==========================================
# 5ï¸âƒ£ Advanced Feature: Auto Health Check
# ==========================================
def health_check():
    health_status = {
        "status": "healthy" if len(df) > 0 else "unhealthy",
        "last_update": str(datetime.now())
    }
    with open("system_health.json", "w") as f:
        json.dump(health_status, f, indent=4)
    logging.info("ğŸ©º Health check file created")

health_check()

# ==========================================
# 6ï¸âƒ£ Advanced Feature: Automated CSV Export
# ==========================================
output_path = "business_impact_results.csv"
df.to_csv(output_path, index=False)
logging.info(f"ğŸ“ Results saved to {output_path}")

# ==========================================
# 7ï¸âƒ£ Metadata Info
# ==========================================
metadata = {
    "Model_Version": "v3.0-Docker",
    "Generated_On": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "Author": "Data Gems Team",
    "Environment": "Docker Container",
    "Notes": "Fully reproducible forecasting system inside container"
}

with open("metadata.json", "w") as f:
    json.dump(metadata, f, indent=4)

logging.info("ğŸ§  Metadata saved successfully")
print("\nâœ… System executed successfully inside Docker container!")
print(f"ğŸ“ Output file: {output_path}")